{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from fancyimpute import KNN\n",
    "from scipy.stats import chi2_contingency\n",
    "from random import randrange, uniform\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Absenteeism_at_work_Project.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].astype('category')\n",
    "\n",
    "df['Reason for absence'] = df['Reason for absence'].replace(0,20)\n",
    "df['Reason for absence'] = df['Reason for absence'].astype('category')\n",
    "\n",
    "df['Month of absence'] = df['Month of absence'].replace(0,np.nan)\n",
    "df['Month of absence'] = df['Month of absence'].astype('category')\n",
    "\n",
    "df['Day of the week']  = df['Day of the week'].astype('category')\n",
    "df['Seasons'] = df['Seasons'].astype('category')\n",
    "df['Disciplinary failure'] = df['Disciplinary failure'].astype('category')\n",
    "df['Education'] = df['Education'].astype('category')\n",
    "df['Son'] = df['Son'].astype('category')\n",
    "df['Social drinker'] = df['Social drinker'].astype('category')\n",
    "df['Social smoker'] = df['Social smoker'].astype('category')\n",
    "df['Pet'] = df['Pet'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making copy of reordered data\n",
    "ordered_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating continous and categrocal variables\n",
    "continuous_variables = [\"Transportation expense\", \"Distance from Residence to Work\", \n",
    "                          \"Service time\" , \"Age\" , \"Work load Average/day \" ,\n",
    "                          \"Hit target\", \"Weight\" , \"Height\", \"Body mass index\",\n",
    "                          \"Absenteeism time in hours\"\n",
    "                        ]\n",
    "\n",
    "categorical_variables = [ \"ID\", \"Reason for absence\", \"Month of absence\", \"Day of the week\",\n",
    "                           \"Seasons\", \"Disciplinary failure\", \"Education\", \"Son\",                \n",
    "                           \"Social drinker\",  \"Social smoker\", \"Pet\"\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing value analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craeating separate dataframe with misssing valuse\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "missing_val = missing_val.reset_index()\n",
    "missing_val = missing_val.rename(columns = {'index' :'Variables',0:'missing_perc'})\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val['missing_perc'] = (missing_val['missing_perc']/len(df))*100\n",
    "missing_val = missing_val.sort_values('missing_perc', ascending=False).reset_index(drop = True)\n",
    "missing_val.to_csv(\"missing_val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Value = 29\n",
    "#Mean = 26\n",
    "#Median = 25\n",
    "#KNN = 27\n",
    "\n",
    "#print(df['Body mass index'].iloc[9])\n",
    "#df['Body mass index'].iloc[9] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n",
    "\n",
    "#Median\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n",
    "\n",
    "#KNN\n",
    "df = pd.DataFrame(KNN(k = 5).fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rounding the values of categorical variables\n",
    "\n",
    "for i in categorical_variables:\n",
    "    df.loc[:,i] = df.loc[:,i].round()\n",
    "    df.loc[:,i] = df.loc[:,i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of Distributed data by graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.factorplot(data=df, x='Reason for absence', kind= 'count',size=3,aspect=2)\n",
    "sns.factorplot(data=df, x='Seasons', kind= 'count',size=3,aspect=2)\n",
    "sns.factorplot(data=df, x='Education', kind= 'count',size=3,aspect=2)\n",
    "sns.factorplot(data=df, x='Disciplinary failure', kind= 'count',size=3,aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Outliers in  data using boxplot\n",
    "sns.boxplot(data=df[['Hit target','Age','Service time','Transportation expense',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Outliers in  data using boxplot\n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df[['Work load Average/day ','Distance from Residence to Work',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting outliers using boxplot and replacing with NA\n",
    "for i in continuous_variables:\n",
    "    q75, q25 = np.percentile(df[i],[75,25])\n",
    "    \n",
    "    # Calculating Interquartile range\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    #calculating upper and lower fences\n",
    "    minimum = q25 - (iqr*1.5)\n",
    "    maximum = q75 + (iqr*1.5)\n",
    "    \n",
    "    #Replace all the outliers with NA\n",
    "    df.loc[df[i]<minimum,i] = np.nan\n",
    "    df.loc[df[i]>maximum,i] = np.nan\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing values with knn\n",
    "df = pd.DataFrame(KNN(k=3).fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values after applying KNN\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking once again for outliers in the data after applying KNN \n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking once again for outliers in the data after applying KNN \n",
    "sns.boxplot(data=df[['Hit target','Age','Service time','Transportation expense',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking once again for outliers in the data after applying KNN \n",
    "sns.boxplot(data=df[['Work load Average/day ','Distance from Residence to Work',]])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Future Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlation analysis\n",
    "#Correlation plot\n",
    "df_cor = df.loc[:,continuous_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for multicollinearity using corelation graph\n",
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "#Generate correlation matrix\n",
    "cor_mat = df_cor.corr()\n",
    "\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(cor_mat, mask=np.zeros_like(cor_mat, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting copy of the data\n",
    "df_old = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable reduction\n",
    "df_new = df.drop(['Body mass index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Columns\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating columns in Continous_variable\n",
    "continuous_variables.remove('Body mass index')\n",
    "continuous_variables.remove('Absenteeism time in hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Future Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of cleaned data\n",
    "#df_cleaned_data = df_new.copy()\n",
    "df_new = df_cleaned_data.copy()\n",
    "df_cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Check\n",
    "for i in continuous_variables:\n",
    "    plt.hist(df_new[i],bins='auto')\n",
    "    plt.title(\"Checking Distribution for Variable \"+str(i))\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of continous variables\n",
    "for i in continuous_variables:\n",
    "    \n",
    "    df_new[i] = (df_new[i] - min(df_new[i]))/(max(df_new[i]) - min(df_new[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy Variable creation for categorical variables\n",
    "df_new = pd.get_dummies(data = df_new,columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of dataframe\n",
    "df_new_dummies = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_new.iloc[:,df_new.columns != 'Absenteeism time in hours' ],df_new.iloc[:, 8],test_size = 0.20, random_state = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Decision Tree------------------------#\n",
    "#Importing libraries for Decision tree regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#create a model decision tree using DecisionTreeRegressor\n",
    "model_DT = DecisionTreeRegressor(random_state = 1).fit(X_train,Y_train)\n",
    "\n",
    "#Predict for the test data\n",
    "predictions_DT = model_DT.predict(X_test)\n",
    "\n",
    "#Create separate dataframe for actual and predicted data\n",
    "df_new_dt_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_DT})\n",
    "\n",
    "print(df_new_dt_pred.head())\n",
    "\n",
    "#Function to create to RMSE\n",
    "def RMSE(y_actual,y_predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual,y_predicted))\n",
    "    return rmse\n",
    "#Calculate RMSE and R-Squared Value\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_DT)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_DT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree                                                                                               \n",
    "RMSE: 3.7141966443496677                                                                                       \n",
    "R-Squared Value: -0.13882343999361768**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------Random Forest------------------------#\n",
    "#Impoorting libraries for Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#create a model Random forest using RandomForestRegressor\n",
    "model_RF = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,Y_train)\n",
    "\n",
    "#predict for test data\n",
    "predictions_RF = model_RF.predict(X_test)\n",
    "\n",
    "#craete a dataframe for actual and predicted data\n",
    "df_new_rf_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_RF})\n",
    "print(df_new_rf_pred.head())\n",
    "\n",
    "#calculate RMSE and RSquared values\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_RF)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_RF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest                                                                                               \n",
    "RMSE: 2.725268748784219                                                                                       \n",
    "R-Squared Value: 0.386880282274243**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------Linear Regression----------------------------#\n",
    "#Import libraries for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create model Linear Regression using LinearRegression\n",
    "model_LR = LinearRegression().fit(X_train,Y_train)\n",
    "\n",
    "#Predict for the test cases\n",
    "predictions_LR = model_LR.predict(X_test)\n",
    "\n",
    "#Create a separate dataframee for the actual and predicted data\n",
    "df_new_lr_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_LR})\n",
    "\n",
    "print(df_new_lr_pred.head())\n",
    "\n",
    "#Calculate RMSE and RSquared values\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_LR)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_LR)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression                                                                                               \n",
    "RMSE: 16390064550.910776                                                                                       \n",
    "R-Squared Value: -2.2176241320666194e+19**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimension Reduction using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a target variable\n",
    "target_variable = df_new['Absenteeism time in hours']\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Converting data into numpy array\n",
    "X = df_new.values\n",
    "\n",
    "pca = PCA(n_components = 115)\n",
    "pca.fit(X)\n",
    "\n",
    "#Proportion of variance\n",
    "var = pca.explained_variance_ratio_\n",
    "\n",
    "#Calculate Screen plot\n",
    "var1 = np.cumsum(np.round(pca.explained_variance_ratio_,decimals=4)*100)\n",
    "\n",
    "#Draw the plot\n",
    "plt.plot(var1)\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Cumulative Proportion of Variance Explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 45 Components since it explains almost 95+ % data variance\n",
    "pca = PCA(n_components=45)\n",
    "\n",
    "#Fitting the selected components to the data\n",
    "pca.fit(X)\n",
    "\n",
    "#Splitting data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,target_variable, test_size=0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Creation after Principal Componet Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Decision Tree------------------------#\n",
    "#Importing libraries for Decision tree regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#create a model decision tree using DecisionTreeRegressor\n",
    "model_DTP = DecisionTreeRegressor(random_state = 1).fit(X_train,Y_train)\n",
    "\n",
    "#Predict for the test data\n",
    "predictions_DTP = model_DTP.predict(X_test)\n",
    "\n",
    "#Create separate dataframe for actual and predicted data\n",
    "df_new_dtp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_DTP})\n",
    "\n",
    "print(df_new_dtp_pred.head())\n",
    "\n",
    "#Function to create to RMSE\n",
    "def RMSE(y_actual,y_predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual,y_predicted))\n",
    "    return rmse\n",
    "\n",
    "#Calculate RMSE and R-Squared Value\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_DTP)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_DTP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree                                                                                               \n",
    "RMSE: 0.07939996345382828                                                                                     \n",
    "R-Squared Value: 0.9994795641369799**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------Random Forest------------------------#\n",
    "#Impoorting libraries for Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#create a model Random forest using RandomForestRegressor\n",
    "model_RFP = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,Y_train)\n",
    "\n",
    "#predict for test data\n",
    "predictions_RFP = model_RFP.predict(X_test)\n",
    "\n",
    "#craete a dataframe for actual and predicted data\n",
    "df_new_rfp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_RFP})\n",
    "print(df_new_rfp_pred.head())\n",
    "\n",
    "#calculate RMSE and RSquared values\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_RFP)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_RFP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest                                                                                               \n",
    "RMSE: 0.05554332987415368                                                                                     \n",
    "R-Squared Value: 0.99974532258328**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------Linear Regression----------------------------#\n",
    "#Import libraries for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create model Linear Regression using LinearRegression\n",
    "model_LRP = LinearRegression().fit(X_train,Y_train)\n",
    "\n",
    "#Predict for the test cases\n",
    "predictions_LRP = model_LRP.predict(X_test)\n",
    "\n",
    "#Create a separate dataframee for the actual and predicted data\n",
    "df_new_lrp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_LRP})\n",
    "\n",
    "print(df_new_lrp_pred.head())\n",
    "\n",
    "#Calculate RMSE and RSquared values\n",
    "print(\"RMSE: \"+str(RMSE(Y_test, predictions_LRP)))\n",
    "print(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_LRP)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression                                                                                               \n",
    "RMSE: 0.0004365935184874104                                                                                   \n",
    "R-Squared Value: 0.9999999842644771**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
